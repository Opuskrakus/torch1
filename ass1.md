# Prerequisites, innan del 1

I del 1 kommer vi bygga vidare p√• implementationen av en enkel artificiell neuron fr√•n lektion 1, m.a.o. f√∂ljande startl√§ge: *(copy-paste fr√•n lektion 1)*

# Kravspecifikation f√∂r del 1

Scope f√∂r **del 1** av denna inl√§mningsuppgift √§r att implementera f√∂ljande versioner av en OCR-perceptron f√∂r handskrivna siffror:

## (A) üßÆ Optional: En enda neuron

- A1: Neuron-implementation: for-loopar och Python-listor (som p√• tavlan lektion 1), ***alternativt***
- A2: Neuron-implementation: NumPy vektor-multiplikation internt i varje Neuron-objekt

## (B) ‚úÖ¬†ANN-lager: NumPy version

Det betyder att vi nu inte l√§ngre beh√∂ver n√•gon klass Neuron, eftersom vi kommer ber√§kna ett helt lager som en enda stor matris-multiplikation:

- Alla input till ett lager = NumPy-vektor
- Alla vikter f√∂r alla neuroner i ett lager = en NumPy-matris
- Observera att vi inte kommer att tr√§na n√§tverket som √§r implementerat som en NumPy-ber√§kning - eftersom det blir mycket enklare i (C) n√§r vi √∂verg√•r till PyTorch.

## (C) ‚úÖ ANN-lager: PyTorch version:

- Anv√§nd PyTorch 2.1 (eller b√§ttre). Anv√§nd helst Python 3.10 (eller b√§ttre).
- Kopplas f√∂rst ihop alla lager i perceptronen s√• att du f√•r en PyTorch-modell (a.k.a. module). Denna definierar i detalj compute-grafen f√∂r din perceptron.
- Anv√§nd d√§refter din perceptron via PyTorch. Googla sj√§lv f√∂r att f√• information om hur detta g√•r till rent praktiskt. Det finns gott om information p√• webben kring PyTorch!
- I denna version ska √§ven tr√§ning av n√§tverket ske, d.v.s. vi ska loopa √∂ver epochs, och applicera back-prop. En vidareutveckling av back-prop som kallas ADAM brukar anv√§ndas eftersom den √§r b√•de snabb och inte lika ofta fastnar i d√•liga lokala minima, j√§mf√∂rt med ren back-prop.
- Se avsnittet ‚ÄúTips f√∂r (C)‚Äù nedan.

## (D) ‚úÖ Samma som (C), men exekverad p√• en CUDA GPU

- GPU:n beh√∂ver st√∂da CUDA v11.6 eller h√∂gre, vilket motsvarar en GPU fr√•n NVIDIA‚Äôs Pascal-generation eller senare (Exempel p√• Pascal-kort: GeForce GTX-1080, Quadro P5000, Tesla P100). (Senare generationer: Volta, Turing, Amp√®re, Ada, Hopper, Blackwell).
- Google Colab har billiga/gratis notebook-instanser med NVIDIA T4 GPU, vilket √§r en enkel type av Turing-GPU. Denna fungerar utm√§rkt f√∂r uppgiften, men har du en modern NVIDIA-GPU i din dator √§r den troligen snabbare √§n en T4.
- Tips kring att anv√§nda GPU f√∂r ber√§kningarna:
    
    ```python
    # Move the model to the GPU# (Otherwise the GPU will not be used!)device = torch.device(f"cuda:0")  # Select the first CUDA GPU in the computermodel  = [model.to](http://model.to/)(device)
    # If you want to list all CUDA-capable GPUs:import os, torch
    if torch.cuda.is_available():
        num_gpus = torch.cuda.device_count()
        print(f"Number of GPUs available: {num_gpus}")
        for i in range(num_gpus):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    else:
        print("CUDA is not available.")
    ```
    

---

## Tips f√∂r (C)

F√∂r uppgift (C) kr√§vs att ni sj√§lva s√∂ker information kring hur man anv√§nder PyTorch. Det finns gott om resurser och dokumentation p√• webben. Om ni v√§ljer att anv√§nda ChatGPT, anv√§nd endast ChatGPT-4 eller b√§ttre, aldrig GPT-3.5. Det √§r viktigt att ni anv√§nder ChatGPT p√• r√§tt s√§tt, d.v.s:

- Anv√§nd g√§rna Chat som hj√§lpmedel f√∂r att se exempel p√• kod, men anv√§nd inte Chat f√∂r att producera kod ni inte f√∂rst√•r. Det √§r viktigt att ni f√∂rst√•r koden som ni l√§mnar in, men det √§r fritt fram att plocka delar fr√•n Chat, Google, StackOverflow, kollegor, etc.
- Om ni l√•ter ChatGPT producera kod f√∂r att l√∂sa delar av uppgiften, s√• √§r ett tips att l√§sa koden tills ni verkligen f√∂rst√•r den, och d√§refter radera koden och g√∂ra om det m.h.a. googling o dyl ist√§llet. Annars riskerar ni att lura er sj√§lva.
- Ett riktigt bra s√§tt att anv√§nda ChatGPT f√∂r att l√§ra sig saker, √§r att ber√§tta f√∂r Chat att du vill l√§ra dig att g√∂ra X. Be Chat skriva korta svar. F√∂rs√∂k att vara specific, och fr√•ga om exakt vad du fastnat p√•. ***Ber√§tta f√∂r Chat att du vill g√∂ra programmeringen sj√§lv*** och att Chat inte ska g√∂ra allt √•t dig. Chat √§r en bra l√§rare, n√§r du ber den vara det. Ber√§tta f√∂r Chat ***hur*** du vill att den ska st√∂dja dig, s√• g√∂r den det!

H√§r √§r en mappning fr√•n den matematik vi har g√•tt igenom (d.v.s. vad du implementerat i uppgift B) till ett par anv√§ndbara klassnamn i PyTorch (nn.Sigmoid & nn.Linear). Observera att man typiskt anv√§nder tv√• ihopkopplade moduler f√∂r att f√• vad vi brukar kalla f√∂r ett neuron-lager. PyTorch ser matrismultiplikation (och addition av bias) som ett f√∂rsta separat steg, och sedan komponent-vis applicering av activation function (t.ex. Sigmoid) som ett efterf√∂ljande steg:
screenshot.png

# Assignment-1-part-1: ANN & CNN

<aside>
üí°

Gl√∂m ej att l√§sa hela uppgiften innan ni b√∂rjar. Det finns anv√§ndbar information i slutet av detta dokument.

</aside>

# Prerequisites, innan del 1

I del 1 kommer vi bygga vidare p√• implementationen av en enkel artificiell neuron fr√•n lektion 1, m.a.o. f√∂ljande startl√§ge: *(copy-paste fr√•n lektion 1)*

- üíª Implementera en egen neuron (med for-loop √∂ver alla inputs) i er personliga Colab-milj√∂.
- üíª Kapsla in funktionaliteten i en Python-klass.
- üöÄ Optional: Implementera n√•gra olika activation functions, t.ex. Sigmoid, ReLU, Leaky-ReLU och Tanh.

---

# Kravspecifikation f√∂r del 1

Scope f√∂r **del 1** av denna inl√§mningsuppgift √§r att implementera f√∂ljande versioner av en OCR-perceptron f√∂r handskrivna siffror:

## (A) üßÆ Optional: En enda neuron

- A1: Neuron-implementation: for-loopar och Python-listor (som p√• tavlan lektion 1), ***alternativt***
- A2: Neuron-implementation: NumPy vektor-multiplikation internt i varje Neuron-objekt

## (B) ‚úÖ¬†ANN-lager: NumPy version

Det betyder att vi nu inte l√§ngre beh√∂ver n√•gon klass Neuron, eftersom vi kommer ber√§kna ett helt lager som en enda stor matris-multiplikation:

- Alla input till ett lager = NumPy-vektor
- Alla vikter f√∂r alla neuroner i ett lager = en NumPy-matris
- Observera att vi inte kommer att tr√§na n√§tverket som √§r implementerat som en NumPy-ber√§kning - eftersom det blir mycket enklare i (C) n√§r vi √∂verg√•r till PyTorch.

## (C) ‚úÖ ANN-lager: PyTorch version:

- Anv√§nd PyTorch 2.1 (eller b√§ttre). Anv√§nd helst Python 3.10 (eller b√§ttre).
- Kopplas f√∂rst ihop alla lager i perceptronen s√• att du f√•r en PyTorch-modell (a.k.a. module). Denna definierar i detalj compute-grafen f√∂r din perceptron.
- Anv√§nd d√§refter din perceptron via PyTorch. Googla sj√§lv f√∂r att f√• information om hur detta g√•r till rent praktiskt. Det finns gott om information p√• webben kring PyTorch!
- I denna version ska √§ven tr√§ning av n√§tverket ske, d.v.s. vi ska loopa √∂ver epochs, och applicera back-prop. En vidareutveckling av back-prop som kallas ADAM brukar anv√§ndas eftersom den √§r b√•de snabb och inte lika ofta fastnar i d√•liga lokala minima, j√§mf√∂rt med ren back-prop.
- Se avsnittet ‚ÄúTips f√∂r (C)‚Äù nedan.

## (D) ‚úÖ Samma som (C), men exekverad p√• en CUDA GPU

- GPU:n beh√∂ver st√∂da CUDA v11.6 eller h√∂gre, vilket motsvarar en GPU fr√•n NVIDIA‚Äôs Pascal-generation eller senare (Exempel p√• Pascal-kort: GeForce GTX-1080, Quadro P5000, Tesla P100). (Senare generationer: Volta, Turing, Amp√®re, Ada, Hopper, Blackwell).
- Google Colab har billiga/gratis notebook-instanser med NVIDIA T4 GPU, vilket √§r en enkel type av Turing-GPU. Denna fungerar utm√§rkt f√∂r uppgiften, men har du en modern NVIDIA-GPU i din dator √§r den troligen snabbare √§n en T4.
- Tips kring att anv√§nda GPU f√∂r ber√§kningarna:
    
    ```python
    # Move the model to the GPU# (Otherwise the GPU will not be used!)device = torch.device(f"cuda:0")  # Select the first CUDA GPU in the computermodel  = [model.to](http://model.to/)(device)
    # If you want to list all CUDA-capable GPUs:import os, torch
    if torch.cuda.is_available():
        num_gpus = torch.cuda.device_count()
        print(f"Number of GPUs available: {num_gpus}")
        for i in range(num_gpus):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    else:
        print("CUDA is not available.")
    ```
    

---

## Tips f√∂r (C)

F√∂r uppgift (C) kr√§vs att ni sj√§lva s√∂ker information kring hur man anv√§nder PyTorch. Det finns gott om resurser och dokumentation p√• webben. Om ni v√§ljer att anv√§nda ChatGPT, anv√§nd endast ChatGPT-4 eller b√§ttre, aldrig GPT-3.5. Det √§r viktigt att ni anv√§nder ChatGPT p√• r√§tt s√§tt, d.v.s:

- Anv√§nd g√§rna Chat som hj√§lpmedel f√∂r att se exempel p√• kod, men anv√§nd inte Chat f√∂r att producera kod ni inte f√∂rst√•r. Det √§r viktigt att ni f√∂rst√•r koden som ni l√§mnar in, men det √§r fritt fram att plocka delar fr√•n Chat, Google, StackOverflow, kollegor, etc.
- Om ni l√•ter ChatGPT producera kod f√∂r att l√∂sa delar av uppgiften, s√• √§r ett tips att l√§sa koden tills ni verkligen f√∂rst√•r den, och d√§refter radera koden och g√∂ra om det m.h.a. googling o dyl ist√§llet. Annars riskerar ni att lura er sj√§lva.
- Ett riktigt bra s√§tt att anv√§nda ChatGPT f√∂r att l√§ra sig saker, √§r att ber√§tta f√∂r Chat att du vill l√§ra dig att g√∂ra X. Be Chat skriva korta svar. F√∂rs√∂k att vara specific, och fr√•ga om exakt vad du fastnat p√•. ***Ber√§tta f√∂r Chat att du vill g√∂ra programmeringen sj√§lv*** och att Chat inte ska g√∂ra allt √•t dig. Chat √§r en bra l√§rare, n√§r du ber den vara det. Ber√§tta f√∂r Chat ***hur*** du vill att den ska st√∂dja dig, s√• g√∂r den det!

H√§r √§r en mappning fr√•n den matematik vi har g√•tt igenom (d.v.s. vad du implementerat i uppgift B) till ett par anv√§ndbara klassnamn i PyTorch (nn.Sigmoid & nn.Linear). Observera att man typiskt anv√§nder tv√• ihopkopplade moduler f√∂r att f√• vad vi brukar kalla f√∂r ett neuron-lager. PyTorch ser matrismultiplikation (och addition av bias) som ett f√∂rsta separat steg, och sedan komponent-vis applicering av activation function (t.ex. Sigmoid) som ett efterf√∂ljande steg:

![](attachment:b8e36811-d9fa-44f1-9bba-92bb1fa41f23:Export-5048730e-6604-4e7e-be29-180733c20e03AI-1_368d73ebc2ac492292ae1213953d00a9_Uppgift_2_Perceptron_for_OCR_9ae6ad9fa43f4c209864974d32cf75a6Screenshot_2024-04-19_at_10.35.13.png)

Screenshot 2024-04-19 at 10.35.13.png

---

## Data f√∂r delmoment 1

Vi kommer att anv√§nda ett v√§lk√§nt kostnadsfritt dataset med 70,000 bilder p√• handskrivna siffror, som redan √§r ‚Äúlabelled‚Äù, vilket betyder att varje bild har en tillh√∂rande klassificering av r√§tt svar (allts√• vilken siffra 0-9 bilden faktiskt visar). Datasettet heter ‚ÄúMNIST‚Äù (‚ÄùModified National Institute of Standards and Technology database‚Äù) och √§r v√§ldigt v√§lk√§nt som ‚ÄúAI:ns Hello World‚Äù.

### Kickstart f√∂r att komma ig√•ng med nedladdning av data

MNIST kan laddas ner p√• flera s√§tt:

1. *Att **tr√§na** version (A) och (B) ing√•r INTE i uppgiften*, men OM ni vill testa det, s√• kan man ladda ner datan s√•h√§r via ett bash-kommando:
    
    ```bash
    pip install get-mnist
    mnist --dataset mnist --cache [YourDesiredDirectory]
    ```
    
2. F√∂r **version (C) och (D)** - Nedan finns *ungef√§rlig* Python-kod, f√∂r att ladda ner datam√§ngden som ett PyTorch dataset. Eftersom MNIST motsvarar AI-v√§rldens ‚ÄúHello World‚Äù, och anv√§nds p√• praktiskt taget alla intro-kurser till AI i hela v√§rlden, s√• finns MNIST som f√∂rberedd metod i *torchvision.datasets*:
    
    ```python
    # filename: mnist_loader.py
    #!/usr/bin/env python3
    
    import torch
    from torchvision import datasets, transforms
    from torch.utils.data import DataLoader
    
    # Skapa en transform f√∂r att redan vid load...
    transform = transforms.Compose([
        transforms.ToTensor(),  # ... 1) konvertera data till [0.0-1.0], och
        transforms.Normalize((0.5,), (0.5,))  # ... 2) normalisera gr√•skalan
    ])
    
    # MNIST √§r s√• vanligt att det finns som funktion i torchvision.datasets
    train_set = datasets.MNIST(
        root='./data', train=True, download=True, transform=transform
    )
    test_set = datasets.MNIST(
        root='./data', train=False, download=True, transform=transform
    )
    
    # Skapa en DataLoader f√∂r tr√§ningsdata och en f√∂r testdata
    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)
    test_loader = DataLoader(test_set, batch_size=64, shuffle=False)
    
    ```
    

---